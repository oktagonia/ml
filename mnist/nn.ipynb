{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np \n",
    "import struct\n",
    "import matplotlib.pyplot as plt\n",
    "from array import array\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNIST:\n",
    "    def __init__(self, path):\n",
    "        self.path = path\n",
    "        self.train_images_path = f'{self.path}/train-images.idx3-ubyte'\n",
    "        self.train_labels_path = f'{self.path}/train-labels.idx1-ubyte'\n",
    "        self.test_images_path = f'{self.path}/t10k-images.idx3-ubyte'\n",
    "        self.test_labels_path = f'{self.path}/t10k-labels.idx1-ubyte'\n",
    "        \n",
    "    def vectorize(self, x):\n",
    "        y = np.zeros((10,1))\n",
    "        y[x] = 1\n",
    "        return y\n",
    "        \n",
    "    def load(self, images_path, labels_path):\n",
    "        with open(labels_path, 'rb') as f:\n",
    "            magic, size = struct.unpack('>II', f.read(8))\n",
    "            \n",
    "            if magic != 2049:\n",
    "                raise ValueError(f'bad magic number, expected 2049 got {magic}')\n",
    "            \n",
    "            labels = [self.vectorize(x) for x in array('B', f.read())]\n",
    "        \n",
    "        with open(images_path, 'rb') as f:\n",
    "            magic, size, rows, cols = struct.unpack('>IIII', f.read(16))\n",
    "            \n",
    "            if magic != 2051: \n",
    "                raise ValueError(f'bad magic number, expected 2051 got {magic}')\n",
    "            \n",
    "            image_data = array('B', f.read())\n",
    "            images = []\n",
    "            for i in range(size):\n",
    "                img = np.array(image_data[i * rows * cols : (i+1) * rows * cols]).reshape(784, 1) / 255\n",
    "                images.append(img)\n",
    "            images = np.array(images) \n",
    "        \n",
    "        return list(zip(images, labels))\n",
    "    \n",
    "    def load_train(self):\n",
    "        return self.load(self.train_images_path, self.train_labels_path)\n",
    "    \n",
    "    def load_test(self):\n",
    "        return self.load(self.test_images_path, self.test_labels_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DifferentiableFunction:\n",
    "    def __init__(self, f, df):\n",
    "        self.f = f\n",
    "        self.deriv = df\n",
    "        \n",
    "    def __call__(self, *args):\n",
    "        return self.f(*args)\n",
    "    \n",
    "sigma = lambda z: 1.0/(1.0 + np.exp(-z))\n",
    "    \n",
    "squared_loss = DifferentiableFunction(lambda y, yhat: (1/2)*np.linalg.norm(yhat - y)**2, lambda y, yhat: yhat - y)\n",
    "sigmoid = DifferentiableFunction(sigma, lambda z: sigma(z) * (1 - sigma(z)))\n",
    "relu = DifferentiableFunction(lambda z: z * (z > 0.5), lambda z: 1 * (z > 0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNet:\n",
    "    def __init__(self, sizes, phis, weights=None, biases=None):\n",
    "        self.sizes = sizes\n",
    "        self.n = len(sizes) - 1\n",
    "        self.phis = phis\n",
    "        self.weights = [np.random.randn(sizes[i+1], sizes[i]) for i in range(self.n)]\n",
    "        self.biases = [np.random.randn(sizes[i+1], 1) for i in range(self.n)]\n",
    "    \n",
    "    def backprop(self, x, y, loss):\n",
    "        weight_deriv = [np.zeros(w.shape) for w in self.weights]\n",
    "        bias_deriv = [np.zeros(b.shape) for b in self.biases]\n",
    "        zs = []\n",
    "        a = x\n",
    "        acts = [x]\n",
    "        \n",
    "        # forward pass\n",
    "        for w, b, phi in zip(self.weights, self.biases, self.phis):\n",
    "            z = w @ a + b\n",
    "            a = phi(z)\n",
    "            zs.append(z)\n",
    "            acts.append(a)\n",
    "                                \n",
    "        # backward pass\n",
    "        delta = loss.deriv(y, acts[-1]) * self.phis[-1].deriv(zs[-1])\n",
    "        bias_deriv[-1] = delta\n",
    "        weight_deriv[-1] = delta @ acts[-2].T\n",
    "        for l in range(2, len(self.sizes)):\n",
    "            z = zs[-l]\n",
    "            phi = self.phis[-l]\n",
    "            delta = (self.weights[-l+1].T @ delta) * phi.deriv(z)\n",
    "            bias_deriv[-l] = delta\n",
    "            weight_deriv[-l] = delta @ acts[-l-1].T\n",
    "        \n",
    "        return weight_deriv, bias_deriv\n",
    "    \n",
    "    def learn(self, dataset, epochs=2, loss=squared_loss, eta=5, minibatch_size=10):\n",
    "        N = len(dataset)\n",
    "        for i in range(epochs):\n",
    "            random.shuffle(dataset)\n",
    "            for j in range(0, N, minibatch_size):\n",
    "                minibatch = dataset[j:j+minibatch_size]\n",
    "                self.learn_minibatch(minibatch, loss, eta)\n",
    "            print(f'Epoch {i}: accuracy = {self.test(dataset)}')\n",
    "    \n",
    "    def learn_minibatch(self, minibatch, loss, eta):\n",
    "        dw = [np.zeros(w.shape) for w in self.weights]\n",
    "        db = [np.zeros(b.shape) for b in self.biases]\n",
    "        \n",
    "        for x, y in minibatch:\n",
    "            weight_deriv, bias_deriv = self.backprop(x, y, loss)\n",
    "            for l in range(self.n):\n",
    "                dw[l] += weight_deriv[l]\n",
    "                db[l] += bias_deriv[l]\n",
    "        \n",
    "        for l in range(self.n):\n",
    "            self.weights[l] -= (eta/len(minibatch)) * dw[l]\n",
    "            self.biases[l] -= (eta/len(minibatch)) * db[l]\n",
    "        \n",
    "    def predict(self, a):\n",
    "        for w, b, phi in zip(self.weights, self.biases, self.phis):\n",
    "            a = phi(w @ a + b)\n",
    "        return a  \n",
    "    \n",
    "    def test(self, test_data):\n",
    "        return sum(int(np.argmax(self.predict(x)) == np.argmax(y)) for x, y in test_data) / len(test_data)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: accuracy = 0.84025\n",
      "Epoch 1: accuracy = 0.8541833333333333\n",
      "Epoch 2: accuracy = 0.8598166666666667\n",
      "Epoch 3: accuracy = 0.86225\n",
      "Epoch 4: accuracy = 0.9445333333333333\n",
      "Epoch 5: accuracy = 0.9479\n",
      "Epoch 6: accuracy = 0.9502166666666667\n",
      "Epoch 7: accuracy = 0.95365\n",
      "Epoch 8: accuracy = 0.9559666666666666\n",
      "Epoch 9: accuracy = 0.9551333333333333\n",
      "Epoch 10: accuracy = 0.9585833333333333\n",
      "Epoch 11: accuracy = 0.9596666666666667\n",
      "Epoch 12: accuracy = 0.9618\n",
      "Epoch 13: accuracy = 0.9640666666666666\n",
      "Epoch 14: accuracy = 0.9629166666666666\n",
      "Epoch 15: accuracy = 0.9651666666666666\n",
      "Epoch 16: accuracy = 0.9665666666666667\n",
      "Epoch 17: accuracy = 0.9668666666666667\n",
      "Epoch 18: accuracy = 0.9676\n",
      "Epoch 19: accuracy = 0.9681333333333333\n",
      "Epoch 20: accuracy = 0.9676166666666667\n",
      "Epoch 21: accuracy = 0.9680333333333333\n",
      "Epoch 22: accuracy = 0.9696333333333333\n",
      "Epoch 23: accuracy = 0.9712833333333334\n",
      "Epoch 24: accuracy = 0.9705666666666667\n",
      "Epoch 25: accuracy = 0.96905\n",
      "Epoch 26: accuracy = 0.9713\n",
      "Epoch 27: accuracy = 0.9710833333333333\n",
      "Epoch 28: accuracy = 0.9719\n",
      "Epoch 29: accuracy = 0.9725833333333334\n"
     ]
    }
   ],
   "source": [
    "mnist = MNIST('mnist')\n",
    "dataset = mnist.load_train()\n",
    "\n",
    "nn = NeuralNet([784, 30, 10], [sigmoid, sigmoid])\n",
    "nn.learn(dataset, minibatch_size=10, epochs=30, eta=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9531"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.test(mnist.load_test())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
